import streamlit as st
import os
import time
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. åŠ è½½é…ç½®
load_dotenv()

# 2. é¡µé¢é…ç½®
st.set_page_config(page_title="Enterprise Secure RAG Portal", layout="wide")

# 3. ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ” Security & Compliance")
    st.success("âœ… Private Link: Active")
    st.success("âœ… Data Residency: East US 2")
    st.info("â„¹ï¸ TLS 1.2 Enforcement: On")
    st.markdown("---")
    st.header("âš™ï¸ Model Parameters")
    temp = st.slider("Temperature", 0.0, 1.0, 0.7)
    st.markdown("---")
    st.caption("Powered by Azure OpenAI (GPT-4o-mini)")

# 4. ä¸»ç•Œé¢
st.title("ğŸ¤– Enterprise Knowledge Assistant")
st.markdown("*Authorized Access Only. All interactions are audited.*")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. å¤„ç†è¾“å…¥
if prompt := st.chat_input("Ask about internal policy..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            api_version="2024-02-01",
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            #æµå¼è¾“å‡º
            response = client.chat.completions.create(
                model=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
                messages=[
                    {"role": "system", "content": "You are a helpful enterprise AI assistant."},
                    {"role": "user", "content": prompt}
                ],
                stream=True
            )
            
            for chunk in response:
                if chunk.choices and chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            # è¿™é‡Œçš„å¼•ç”¨æºæ˜¯é™æ€å±•ç¤ºï¼Œä¸ºäº†æ¼”ç¤ºæ•ˆæœ
            with st.expander("ğŸ“š Data Governance & Citations (Private Link Verified)"):
                st.markdown(f"""
                - **Source:** `internal_policy_doc_v2.pdf`
                - **Vector DB:** Azure AI Search (10.0.1.5)
                - **Latency:** 320ms
                """)

        st.session_state.messages.append({"role": "assistant", "content": full_response})

    except Exception as e:
        st.error(f"Error: {str(e)}")